{
  "cells":[
    {
      "cell_type":"code",
      "source":[
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb"
      ],
      "execution_count":36,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# read all features\n",
        "features = pd.read_pickle('.\/data\/features')\n",
        "# They are encoded as follows:\n",
        "'''\n",
        "0 - Degreee Number\n",
        "1 - Core Number\n",
        "2 - Page Rank\n",
        "3 - Avg. H-Index\n",
        "4- Top Cited Paper (Dummy)\n",
        "5 - 104 Word2Vec Embeddings\n",
        "105 - 154 Graph Embeddings\n",
        "'''\n",
        "# read the training data\n",
        "df_train = pd.read_csv('.\/data\/train.csv', dtype={'author': np.int64, 'hindex': np.float32})"
      ],
      "execution_count":37,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "y_train = df_train['hindex']"
      ],
      "execution_count":38,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Base Model"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Getting the data for the base model\n",
        "X_train = features.iloc[:,:2]"
      ],
      "execution_count":6,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=42\n",
        ")"
      ],
      "execution_count":7,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "reg = lgb.LGBMRegressor(n_estimators = 500,learning_rate = 0.12, num_leaves = 150)\n",
        "reg.fit(X_train1, y_train1)\n",
        "y_pred1 = reg.predict(X_test1)"
      ],
      "execution_count":8,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "print(\"MSE for baseline model: \", mean_squared_error(y_test1, y_pred1))"
      ],
      "execution_count":9,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "MSE for baseline model:  105.38829642483441\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Pagerank"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Getting the data for the base model and adding pagerank\n",
        "X_train = pd.concat([features.iloc[:,:2],features.loc[:,2]], axis=1)"
      ],
      "execution_count":10,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=42\n",
        ")"
      ],
      "execution_count":11,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "reg = lgb.LGBMRegressor(n_estimators = 500,learning_rate = 0.12, num_leaves = 150)\n",
        "reg.fit(X_train1, y_train1)\n",
        "y_pred1 = reg.predict(X_test1)"
      ],
      "execution_count":12,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "print(\"MSE for pagerank added: \", mean_squared_error(y_test1, y_pred1))"
      ],
      "execution_count":13,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "MSE for pagerank added:  103.30533662927053\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Average H-Index"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Getting the data for the base model and adding average h-index\n",
        "X_train = pd.concat([features.iloc[:,:2],features.loc[:,3]], axis=1)"
      ],
      "execution_count":44,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=42\n",
        ")"
      ],
      "execution_count":45,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "reg = lgb.LGBMRegressor(n_estimators = 500,learning_rate = 0.12, num_leaves = 150)\n",
        "reg.fit(X_train1, y_train1)\n",
        "y_pred1 = reg.predict(X_test1)"
      ],
      "execution_count":46,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "print(\"MSE for average h-index added: \", mean_squared_error(y_test1, y_pred1))"
      ],
      "execution_count":47,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "MSE for average h-index added:  86.74902864269235\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Top cited paper (Dummy)"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Getting the data for the base model and adding top cited paper (Dummy)\n",
        "X_train = pd.concat([features.iloc[:,:2],features.loc[:,4]], axis=1)"
      ],
      "execution_count":39,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=42\n",
        ")"
      ],
      "execution_count":40,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "reg = lgb.LGBMRegressor(n_estimators = 500,learning_rate = 0.12, num_leaves = 150)\n",
        "reg.fit(X_train1, y_train1)\n",
        "y_pred1 = reg.predict(X_test1)"
      ],
      "execution_count":41,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "print(\"MSE for top cited paper (Dummy) added: \", mean_squared_error(y_test1, y_pred1))"
      ],
      "execution_count":42,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "MSE for top cited paper (Dummy) added:  97.35953757539404\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Word2Vec Embeddings"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Getting the data for the base model and adding word2vec embeddings\n",
        "X_train = pd.concat([features.iloc[:,:2],features.loc[:,5:104]], axis=1)"
      ],
      "execution_count":26,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=42\n",
        ")"
      ],
      "execution_count":27,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "reg = lgb.LGBMRegressor(n_estimators = 500,learning_rate = 0.12, num_leaves = 150)\n",
        "reg.fit(X_train1, y_train1)\n",
        "y_pred1 = reg.predict(X_test1)"
      ],
      "execution_count":28,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "print(\"MSE for Word2Vec Embeddings added: \", mean_squared_error(y_test1, y_pred1))"
      ],
      "execution_count":29,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "MSE for Word2Vec Embeddings added:  55.73936707760211\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Graph Embeddings"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Getting the data for the base model and adding graph embeddings\n",
        "X_train = pd.concat([features.iloc[:,:2],features.loc[:,105:154]], axis=1)"
      ],
      "execution_count":30,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=42\n",
        ")"
      ],
      "execution_count":31,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "reg = lgb.LGBMRegressor(n_estimators = 500,learning_rate = 0.12, num_leaves = 150)\n",
        "reg.fit(X_train1, y_train1)\n",
        "y_pred1 = reg.predict(X_test1)"
      ],
      "execution_count":32,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "print(\"MSE for graph embeddings added: \", mean_squared_error(y_test1, y_pred1))"
      ],
      "execution_count":33,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "MSE for graph embeddings added:  90.70049364241065\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}